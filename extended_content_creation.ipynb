{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import functions as funs\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenews = set(['fake', 'conspiracy'])\n",
    "relevant = ['reliable', 'fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_content = pd.read_pickle('data/labeled_content_new.pkl')\n",
    "labeled_content = pd.DataFrame(labeled_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['content', 'type'], dtype='object')\n",
      "4449\n"
     ]
    }
   ],
   "source": [
    "#labeled_content_extended\n",
    "scraped_data_content = pd.read_pickle('data/scraped_data_preprocessed.pkl')\n",
    "scraped_data_content = pd.DataFrame(scraped_data_content)\n",
    "\n",
    "#Creating column of reliable labels\n",
    "scraped_data_content['type'] = 'reliable'\n",
    "#Renaming 'text' column to 'content'\n",
    "scraped_data_content.rename(columns={'text' : 'content'}, inplace=True)\n",
    "print(scraped_data_content.columns)\n",
    "print(len(scraped_data_content))\n",
    "\n",
    "#Concatenating original data with extra scraped data\n",
    "labeled_content_extended = pd.concat([labeled_content, scraped_data_content],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425210\n"
     ]
    }
   ],
   "source": [
    "print(len(labeled_content_extended))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_content_extended.to_pickle('labeled_content_extended_new.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
