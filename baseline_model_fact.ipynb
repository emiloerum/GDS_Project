{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#functions module contains all the functions we defined ourselves\n",
    "import functions as funs\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenews = set(['fake', 'conspiracy'])\n",
    "relevant = ['reliable', 'fake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_content = pd.read_pickle('data/labeled_content.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = labeled_content['content']\n",
    "y = labeled_content['type'].apply(lambda x: funs.bin_target(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train, validation and test sets\n",
    "X_train, X_val, y_train, y_val= train_test_split(X,y,test_size=0.2,random_state=0,shuffle=True)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val,y_val, test_size=0.5,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6211617073866337\n"
     ]
    }
   ],
   "source": [
    "#baseline2: logistic regression, \"fact\"-mentions in each document\n",
    "accuracy_of_factcount_baseline = funs.reg_from_one_word(X_train, X_val, y_train, y_val, \"fact\")\n",
    "print(accuracy_of_factcount_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in labeled content with extra scraped data\n",
    "labeled_content_extended = pd.read_pickle('data/labeled_content_extended.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into feature and target\n",
    "X = labeled_content_extended['content']\n",
    "y = labeled_content_extended['type'].apply(lambda x: funs.bin_target(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting extended data into train, validation and test sets\n",
    "X_train, X_val, y_train, y_val= train_test_split(X,y,test_size=0.2,random_state=0,shuffle=True)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val,y_val, test_size=0.5,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6221866842266174\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_of_factcount_baseline_extended = funs.reg_from_one_word(X_train, X_val, y_train, y_val, \"fact\")\n",
    "print(accuracy_of_factcount_baseline_extended)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
