{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astri\\AppData\\Local\\Temp\\ipykernel_18684\\4080736814.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar = pd.read_pickle(\"labeled_liar_statements_preprocessed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news = pd.read_pickle(\"labeled_content.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number': 5520,\n",
       " 'state': 1701,\n",
       " 'percent': 1497,\n",
       " 'year': 1456,\n",
       " 'tax': 1283,\n",
       " 'obama': 1089,\n",
       " 'presid': 833,\n",
       " 'job': 818,\n",
       " 'vote': 812,\n",
       " 'health': 776,\n",
       " 'million': 754,\n",
       " 'peopl': 747,\n",
       " 'care': 655,\n",
       " 'bill': 577,\n",
       " 'american': 551,\n",
       " 'time': 527,\n",
       " 'nation': 523,\n",
       " 'countri': 518,\n",
       " 'billion': 515,\n",
       " 'rate': 513}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vocabulary_size(series):\n",
    "    '''Computes the vocabulary size of a corpus by iterating through every word\n",
    "    in every document in the corpus and adding it to a dictionary if it hasnt been seen before\n",
    "    as well as incrementing a variable counting every unique word. Returns the unique_word_count\n",
    "    and sorted list of words and their frequencies'''\n",
    "    # Initialize a counter for unique words count and dictionary to store word frequencies\n",
    "    unique_words_count = 0\n",
    "    word_frequency = {}\n",
    "    # Iterate through each element in the series\n",
    "    for field in series:\n",
    "        # Iterate through each word in the current element\n",
    "        for word in field:\n",
    "            if word in word_frequency: \n",
    "                # If word already in dict, increment its count\n",
    "                word_frequency[word] += 1\n",
    "            else:\n",
    "                # If not add it to the dictionary with count 1 and increment unique_words_count\n",
    "                word_frequency[word] = 1\n",
    "                unique_words_count += 1\n",
    "    # Sort the word_frequency dictionary by frequency in descending order\n",
    "    sorted_word_frequency = sorted(word_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return unique_words_count, sorted_word_frequency\n",
    "\n",
    "def most_frequent(series, from_value, to_value):\n",
    "    '''returns a dictionary containing the\n",
    "   \"n\" most frequent words in an interval - [from_value:to_value] - in the input series.'''\n",
    "    return dict(vocabulary_size(series)[1][from_value:to_value])\n",
    "\n",
    "frequent_stemwords_liar = most_frequent(liar[\"Statement\"], 0, 20)\n",
    "frequent_stemwords_liar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar = pd.concat([pd.read_csv(\"train.tsv\", sep=\"\\t\",header=None),pd.read_csv(\"test.tsv\", sep=\"\\t\",header=None),pd.read_csv(\"valid.tsv\", sep=\"\\t\",header=None)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0            1                                                  2   \\\n",
      "0   2635.json        false  Says the Annies List political group supports ...   \n",
      "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
      "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
      "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
      "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
      "\n",
      "                                   3               4                     5   \\\n",
      "0                            abortion    dwayne-bohac  State representative   \n",
      "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
      "2                      foreign-policy    barack-obama             President   \n",
      "3                         health-care    blog-posting                   NaN   \n",
      "4                        economy,jobs   charlie-crist                   NaN   \n",
      "\n",
      "         6           7     8     9      10     11    12                   13  \n",
      "0     Texas  republican   0.0   1.0    0.0    0.0   0.0             a mailer  \n",
      "1  Virginia    democrat   0.0   0.0    1.0    1.0   0.0      a floor speech.  \n",
      "2  Illinois    democrat  70.0  71.0  160.0  163.0   9.0               Denver  \n",
      "3       NaN        none   7.0  19.0    3.0    5.0  44.0       a news release  \n",
      "4   Florida    democrat  15.0   9.0   20.0   19.0   2.0  an interview on CNN  \n"
     ]
    }
   ],
   "source": [
    "print(liar.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      dwayne-bohac\n",
       "1    scott-surovell\n",
       "2      barack-obama\n",
       "3      blog-posting\n",
       "4     charlie-crist\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "liar[4].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['President',\n",
       " 'U.S. Senator',\n",
       " 'Governor',\n",
       " 'President-Elect',\n",
       " 'U.S. senator',\n",
       " 'Presidential candidate',\n",
       " 'Former governor',\n",
       " 'U.S. Representative',\n",
       " 'Senator',\n",
       " 'Milwaukee County Executive']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "liar[5].value_counts()[:n].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a news release',\n",
       " 'an interview',\n",
       " 'a press release',\n",
       " 'a speech',\n",
       " 'a TV ad',\n",
       " 'a tweet',\n",
       " 'a campaign ad',\n",
       " 'a television ad',\n",
       " 'a radio interview',\n",
       " 'a debate']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "liar[13].value_counts()[:n].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['barack-obama',\n",
       " 'donald-trump',\n",
       " 'hillary-clinton',\n",
       " 'mitt-romney',\n",
       " 'john-mccain',\n",
       " 'scott-walker',\n",
       " 'chain-email',\n",
       " 'rick-perry',\n",
       " 'marco-rubio',\n",
       " 'rick-scott']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "liar[4].value_counts()[:n].index.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
